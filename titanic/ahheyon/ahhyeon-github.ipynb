{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "111cd03d",
   "metadata": {},
   "source": [
    "# 사이킷런으로 수행하는 타이타닉 생존자 예측\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97af1cf",
   "metadata": {},
   "source": [
    "목적: 이름, 사회적 계층등을 기준으로 하여 생존율이 더 높게 나올 수 있도록 예측해주는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d1507155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "829fab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df=pd.read_csv('C:/Users/ns451/Documents/python/머신러닝/파이썬 머신러닝 완벽가이드/titanic_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cbe32677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0805d4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7b4f3ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c73cee9",
   "metadata": {},
   "source": [
    "### 결측값 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "34c439f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#결측값을 평균으로 대체하기\n",
    "#.확인하기\n",
    "titanic_df.isnull().sum() #Age            177,Cabin          687,Embarked         2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "827b7114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. 연속형 함수: 평균으로 대체\n",
    "titanic_df['Age'].fillna(titanic_df['Age'].mean(),inplace=True)\n",
    "#2. 불연속형 함수: N값으로 채우기\n",
    "\n",
    "titanic_df['Cabin'].fillna('N',inplace=True)\n",
    "titanic_df['Embarked'].fillna('N',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1ab0370b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3fa1651a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          891 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        891 non-null    object \n",
      " 11  Embarked     891 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#불연속형 함수에 대해 feature 내 특징 비교하여 확인해보기\n",
    "#1. type 확인하기\n",
    "titanic_df.info()\n",
    "#Sex Ticket Cabin        Embarked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05254cb9",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ccdcc3",
   "metadata": {},
   "source": [
    "### cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "643cf5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      N\n",
       "1      C\n",
       "2      N\n",
       "3      C\n",
       "4      N\n",
       "      ..\n",
       "886    N\n",
       "887    B\n",
       "888    N\n",
       "889    C\n",
       "890    N\n",
       "Name: Cabin, Length: 891, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#titanic_df['Cabin']의 문제점\n",
    "# -->한꺼번에 표기된 값이 보인다.\n",
    "\n",
    "\n",
    "\n",
    "#1번째 문자 표기하기\n",
    "titanic_df['Cabin']=titanic_df['Cabin'].str[:1]\n",
    "titanic_df['Cabin']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e51b665",
   "metadata": {},
   "source": [
    "### Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3b13a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#영문자만 넣기\n",
    "import re\n",
    "titanic_df['Ticket'] = [re.sub('[^A-Za-z]', '', s) for s in titanic_df['Ticket']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2b93941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공백값을 nan으로채우기\n",
    "titanic_df['Ticket']=titanic_df['Ticket'].replace('','NAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb31a83f",
   "metadata": {},
   "source": [
    "### NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "484c9ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-90-ccde30a62b04>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  titanic_df['Name'][i]=titanic_df['Name'][i].split(',')[1]\n"
     ]
    }
   ],
   "source": [
    "#,와 . 사이의 특정값을 가져오기\n",
    "import re\n",
    "#1. 쉼표기준\n",
    "for i in range(len(titanic_df['Name'])):\n",
    "    titanic_df['Name'][i]=titanic_df['Name'][i].split(',')[1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "49e1de18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-91-40744a052a23>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  titanic_df['Name'][i]=titanic_df['Name'][i].split('.')[0]\n"
     ]
    }
   ],
   "source": [
    "#2.온점기준\n",
    "for i in range(len(titanic_df['Name'])):\n",
    "    titanic_df['Name'][i]=titanic_df['Name'][i].split('.')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86694377",
   "metadata": {},
   "source": [
    "### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9177fb74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Name 별 생존율')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbAAAAEGCAYAAAAE3cBCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAeSElEQVR4nO3de7ylc93/8dfbOUVipojGCBElD3ZRToMObsdO7mpKUZlSlMOdVPyayu0hQicqEmpCScmpnMdhDNmjEN2kbrpVMuXQZDAN798f13ebNXuvvfbaM3utZe31fj4e++Ha13Wta32umXmsj++1ruv9lW0iIiK6zTKdLiAiImJJpIFFRERXSgOLiIiulAYWERFdKQ0sIp4l6T+W8vWvlrTiWNUT0YhyF2JE75C0L7CO7aNr1t1ne/Lg5RGO81vbrxp8DEkzgX1t31fWbwKcXfPSlwHzgEfL7/Ntv2HQsVcFvgS8FlgIGFgOOB84yfnQimK5ThcQER23Zmk8TZEkYI1m9rV9F7B5ed1ywG3ANbYPbPCyk4BbbX+y5j1XBH4AvIfFG2L0sFxCjGgRSfdJuqx84Neuf7RDJQ04QFL/wA/wEPDW8tOMV1I1vQ2bfUNJz6dqQOcCG0r6aIPd5wIbS1qrvFbABsBLy7YIIJcQI1pG0n3A74Gf2T6lZv2jtlfrUE37MvQS4r+An5Rfp4x0CVHSGcCLqS7/7V3WPQXcAWwEvLrmEuIWwFuoRk4n2D6rjKaOA14DnAVcYfuBmuMvA3wI2JVqpPcM8CfgLNtXLc35x/iSS4gRrfUx4DJJl9u+d/BGSZ+j+qAW8CDwbtsLyiW9K4HXUzWFo4CXAztTNY/DbF9WjvEW4NPlkPOB/W3/tUFNH5f0zprf/25733Ks+xqdjKSDgBcCewDfkXQKcCjwV9t9dS5Frl3Oaxvb8yQdCcy2/UlJ65TjvKD2BbafAU4rPxHDSgOLaK25wCeBsyRtVz6ca11q+78BJP0Y2JNFo6EX2N5N0rrAncBRtneS9DrgW1SNcT2qBrKr7Scl7Q0cTTWCGcL2mcCZDer94XAbJK1PdSnv3bafkTQN2B9YdrjX2L5o0Ko1gVXKtgfKeQwcfzeqRg0wAVgJGBiZbQLcCywov+9hO5cTe1wuIUa0SBnNbG77UUmnAffa/nLtJcTyPdJbqT6gtwW+aftrZSTzads3l/0eAPpsPyhpeeBB22tI+hhwGPB/5W2XA/5he68Gda0FDG4sA/5ie88mzm0Nqub1OmB14HHgQmAm8Efb/5a0J/DFkY5VvNn2Q+XYr6C65Pgy4Ltl+3eAI4GbB/aLyAgsoj0OAW6WdCnVbeEDzesnVCO0M8o+tTd8PFWzvBB4EqA0h4FRz3LAubY/12wh5fJiX71tkoZc5qyzz4uoGtU3qS6RPgysBewHfNv2juV9LgQuLJc477D9lyZLXAv4Q/nZoKw7nqqprQ18u8njxDiXBhbRBrb/JWl/qkY1cBlxM+Au2zMlPQ/4D+D7ozz0VVRN4mu2H5K0CvBS23cP9wJJLwUuAZ6uV2oT77kd0G/7OzXr7gemS7pF0stt/7Fm2z5UTafZBvYWYPs669cGrmvyGNED0sAi2sT2jZIuAz5bVv0S+JCk2VS3sv96CY55p6QvUH0fNo+qOX56hJetADxme8po36+4DThe0ma2bx9YWVI8VmXR5cwltQlwoO3fLOVxYpzLd2ARPUbSZOC3VDdF1POuRiO4coytgM8BE8uq5YDfAdMHjb6QNAPYiup7ssEutP3/Bu1/AdUdl/Pr7H+D7f9qVFv0jjSwiIjoSkniiIiIrpQGFhERXSkNLCIiulLuQmyjCRMmePLkyZ0uIyKia8yZM+fvtifW25YG1kaTJ0+mv7+/02VERHQNSfcPty2XECMioiulgUVERFdq+SVESWsCL7R9d3mA8ljb717CY21BlbT9IqrImxm18yyNQa1TbM8cq+MN8fAcOFsj7xcRMV5Mbd2zxu34DmwXqmkRGj7ZPxJJG1CFh06tmSxvxaWubnHHAluP8TEjIqIFWnoJUdKWwBHAoZKOK6tXkTRD0q2Svlb2W1bStyRdI+mqMsfRYAcDRw40LwDbT5XXf1jSDZKuK8deUdJkSefW1HJuWTdZ0qWSfihpjqTjy/bzgE0kzZS0uqQ9JV0vaZak/co++0u6sfxsLWmDUvP1ko4mIiLapqUjMNtzJB0LrGT72+US4iuBV1PlnP1a0mrAO4G7bR8gaROqeX8GT8i3IfCbwe8haSPg7VRToS+U9ClgGsPPdwRl2nPgCeBWSava3lvSTbanlJoOBnaimsbiSknnlJp2sj2/THt+ENVlzNPL70OUSf+mAUya0KCiiIgYlU7cxNFv+3FXIYx3A6sBWwDvLZP4nUKVaD3Yn4D166zfDLjS9sLy+5XAxjSeFqLf9vxSwz1U36nVegVVw7wCuAZ4SfnZHzhG0hFUid6nAWtJOpGqKQ5h+1Tbfbb7Jq7SoKKIiBiVdjSwp4Ha76pqp1QfaDL3AF+3PaVM8fCBOsc5FfiKpGfHMZKeT5WAvXPNBH87UU1L8TDV9OUDNqhZ9qDlgTsrli///V/gdmDHUs/rbN9PNaPuwcAjVM3Mto8GpgPfq1NzRES0SDtu4pgNXCxpIoumBx/sVOAMSR+mmnLheKqRz7Ns31IuR54vCarGeLrtH0r6BTBL0nzgTuBg20+X76pOpppraUETtf5R0vXAnsAFwGxJ/wRuBo4CzimXFxcCBwBTS81PAWeNePTVt4SpeZA5ImIsZDqVNurr63OSOCIimidpju2+etvyIHNERHSlNLCIiOhKaWAREdGV0sAiIqIrZTqVdkoWYkT0mhZmIWYE1gRJW0m6rMRG/VrSmpI2l/S+TtcWEdGrMgJrzleAvWw/XB6Ylu0HGRRtJUnOcwkREW2REVhz/gC8EcD20yVzcUp5sJoSAHwEcEkni4yI6CVpYM35MDBJ0kWShptu5Vbbuw5eKWmapH5J/XPntbbIiIhekgbWBNsLbX8FmAocKek1dXa7cZjXJsw3IqIF0sCaIGldANvzgF9RpdUPtrDOuoiIaJHcxNGcEyS9DPgXcB/VzM1vGPVREuYbETFm0sCaYPuddVbPLD+UKVciIqKNcgkxIiK6UhpYRER0pTSwiIjoSmlgERHRldLAIiKiK6WBDSJpuqTbJV0raZakLTpdU0REDJUGVt/htnegipA6qtPFRETEUGlgja0PPAAg6fUltPc6SUdKWlnSrwZ2lHSIpPcPPsBiWYhz57ax9IiI8S0NrL7jJP0ReDdwuCRRTamyp+3tgVcBE4E5kl5XXrM78OPBB1osC3HixDaVHxEx/iWJo77DqTIPLwVWB/5NlX94YdXLWA1YBzgd+ICkhVRp9E92pNqIiB6UBjaMMnnlZ4ETqFLo/wd4s+0Fkla2PR+gzAm2L/D1jhUbEdGDcgmxAdtXA8sCOwLHAddJugL4as1uFwLr2L63/RVGRPQu2e50DT2jr6/P/f1Jo4+IaJakObb76m3LCCwiIrpSGlhERHSlNLCIiOhKaWAREdGVchv9MCRNB3axvfWg9YcBu9vecdQHfXgOnK2xKTAiohtMbd2NghmBNbaypG0HfpG0PPAm4JnOlRQREZAGNpKTgU/W/P4+4CKqZ8OQtKekGyXdIOltnSgwIqJXpYE1dj/whKQNSx7ie4EZNdv3A/axvS3w83oHWCzMd17rC46I6BVpYCM7ATgE2AO4EniqZtvBwEclfRFYtd6LFwvzXaXVpUZE9I40sBHYvg1YEzgI+PagzQ/Z/hQwi8wbFhHRVrkLsTknA7vZflTSSjXrT5S0KfA08LkRj7L6ljA1UVIREWMhWYhtlCzEiIjRSRZiRESMO2lgERHRldLAIiKiK6WBRUREV0oDi4iIrpTb6Gu0JMC3VsJ8I3pHC0Nso5IR2FAJ8I2I6AJpYEONFOC7r6RvSLpG0jaSPl8CfW+SNKkTBUdE9KJcQhzq2QBf4F6qAN93AHvX7LPGwOVESacAm9t2CfxdjKRpwDSASRNaXXpERO/ICKy+RgG+ADfWLB8IfF3Sx4EhDSxhvhERrZEGVscIAb4AC2uW+20fBKwD7NaG8iIiglxCbGS4AN9nSVoGuErSU8B84MSGR0yYb0TEmEmYbxslzDciYnQS5hsREeNOGlhERHSlNLCIiOhKaWAREdGV0sAiIqIr5Tb6BsY83He8hPkmpDQingMyAhtZwn0jIp6D0sBGNqpw304UGBHRi9LARvZsuG8J630vMGPQPmvY3tH2rMEvljRNUr+k/rnz2lFuRERvSANrzmjCfReTMN+IiNbITRxNsH2bpIFw373r7LKwzrqIiGihNLDmjRjuO6KE+UZEjJmE+bZRwnwjIkYnYb4RETHupIFFRERXSgOLiIiulAYWERFdKXchttN4yUKMiGhWC7NTe3IEJmm6pJvqrD9M0jWdqCkiIkanJxtYkZDeiIgu1ssNrJmQ3pMlnSfp15K2k3SJpDsl/WfZZ01JP5d0taQfSVph8JskCzEiojV6uYE1E9K7su29gaOAU4C3AVOochEBjgem294JuBZ41+A3SRZiRERr9PpNHAMhvb+kfkjvr8p/7wVutb0AmFsuNwJsBpxU9T9WAs5recUREQH0eANrIqTXwywP+D3wX7bvk7QMsHydfSIiogV6uoEVSxPS+1nge2UE9hjwMeCvw+6dMN+IiDGTMN82SphvRMToJMw3IiLGnTSwiIjoSmlgERHRldLAIiKiK+UuxHZKmG9E9JqE+bZOM8G+JVbqo2V5yL4REdF+Pd/AigT7RkR0mTSwSsNg33okvUDS2SXI92JJqw+zX8J8IyJaIA2s0kyw72BHAD8uQb6nAB+vt1PCfCMiWiM3cSwyUrDvYFsAO0g6mOrP8ZaWVhcREYtpqoFJWpdqSpFVgA8AW9m+tpWFtVsTwb6D3QOcb/t6AEnPG/EVyUKMiBgzzV5C/C7VCGWi7SeBT7WupI46GbjD9qNN7HsM8BlJ10i6CFi/pZVFRMRimr2EuIzt35XUdYAXtKietrM9vWb5KuCqsvwk1eSV2D6zZp+ty38fAnZtX6UREVGr2RHY3ZI+ATxf0nuBB1tYU0RExIiabWAHAo8D/cAawH4tqygiIqIJTV1CtP2MpBlUz0ZBdTPHEy2rKiIiYgTN3oV4ArAz8CdAgIE9W1hXREREQ83exLGt7c1bWUinSJoO7DJwc0bN+sOA3W3vKOktwDO2r1iqN0uYb0T7tTBMNjqr2e/A7pE0qaWVdFbDLETbly1184qIiDHVbAM7B7hD0k2SZku6sZVFdUDDLMSBNHpJK0n6kaQbJF1Stu0v6cbys/XQQ0dERCs0ewnxWGCy7UdaWUwHPZuFCNxLlYX4DoYmcmwELLC9raSB5v8hYCfb82vWPUvSNGAawKQJrSo/IqL3NDsCuwn4ZysLeQ4YyELcg2GyEG3fBlwt6RvAm8vq/YFjJB0BrFDnNQnzjYhogWYb2NrAbyWdU37ObmVRnVCa00AW4rfr7SNpJeBM2wcBR0paDbjX9sHAI1TNLCIi2qDZS4gfa2kVzx0nA7vZfrQ0q8E2Bk6V9C/gzrLfBaWRLQQOaHj0hPlGRIwZ2SPfYippWeB1VA8wA2D78hbWNS719fW5vz8NLCKiWZLm2O6rt63ZEdjPgLnAZOBfwKNAGlhERHRMs9+BrWL7Q8CvbO8FjDz3VURERAs128CekLQcsIqklwCbtrCmiIiIETXbwD5GNeo6CziN6rmwiIiIjmk2jf6+sngLCfGNiIjngIYNTNI1VMnztQxge+dWFbW0mgnoHcWx1geesv3AUheWMN8YrxKYGx0w0ghsl0G/TwROApb+w7z1Vpa0re0bYGhA7yjsQ5VEMuI5S5KbeS4hIiKWWsMGZvvZOCVJ76Gamflw27NaXdgYGAjovaH8PhDQuzeApPWAU4CVgXnA24B1qb7jWw64FpgN7Au8XdImwKnlZ01gPvB+2w9Luhn4LfA34LNtOLeIiJ434ndgktYEvgX8AdjZ9pMtr2psjBTQ+w9gL9sLJH2P6kHtPmCG7dMlLVNmon4tcJPtX0o6Gvix7Qsk7Qp8HPgSVULH7rbnDi4iYb4REa0x0ndg+1F9+B5i+6b2lDSmBgJ6f8nQgN6NgQ9ImgesR5UychpwqKQTy/LvBh1vC2AHSQdT/dndUtb/vl7zgirMl2rURt/LlcuLERFjZKQR2OnAr4GTpGc/fAXY9htaWtkYsH1bGUEexNCpUY4Cptn+q6QLF73ER0taFbgMeD3wNLBi2X4PcL7t6wEkDTzQvbCV5xEREUON9B1Ys8+JPZcNF9B7HnCVpLuAx8q6qZI+TDVSO6usuxo4Q9I6wDHAmZK+SBWp9Rmq776akzDfiIgx01SYb4yNhPlGRIxOozDf8TDCioiIHpQGFhERXSkNLCIiulIaWEREdKVmJ7SMsZAsxOiUZBXGONQTIzBJ0yUNeRBb0mElsHi4161dHlqOiIjnmJ5oYMXKkrYd+KWZcF/bf7b91TbUFhERo9RLDWwg3HfAQLjvslCF+0r6haRrJV0saXlJkyWdW7ZvLOmXkq6RdJ2kLcv6M8sI72ZJy7b7pCIielUvNbBnw30liSrcd0bN9oFw3x2Ah6jCfWt9E/hEmUtsH+CrNdv+Ynsr208PflNJ0yT1S+qfO28MzyYiosf12k0cow33rfV82/cA2L5fUu2f3Y3DvWHCfCMiWqOnGtgShPvWWiBpA9v3SnoZ8M+abQnzjYhos55qYMVown2XYVFzOhA4tVx+fAL4xKjfOWG+ERFjJmG+DUjaHXit7c+PxfES5hsRMTqNwnx7cQTWFEkzgX9T3a0YERHPMWlgw7A9pdM1RETE8HrpNvqIiBhH0sAiIqIr5RJiOyXMNyJ6TQuDpHt6BFYioHZZgtcNCQaOiIj26ukGFhER3SsNbBBJ+0m6StIcSdPKurVL0O9Vko4r614q6Yqa1x1dbzSXLMSIiNZIAxvqYts7A9sDB5R1XwaOLuvPA7D9F+DvkjYouYjbApcNPpjtU2332e6bODhdMSIillhu4hjqA5JeTBUhNRA1tb7tWWW5NkrjG8AHgVuB851Yk4iItskIrIakNYA32T6cavqU55VNj0jarCzvCBjA9o3AplRTs5zZ3mojInpbRmBwnKQjyvL+wHxJs4BZVPOCAXwGOE3SfOByoHber8uBjWyP/A1XwnwjIsZMwnyXkqSLgENt/36kfRPmGxExOo3CfHMJcQlJWlPSzcC1zTSviIgYW7mEuIRsPwhs1ek6IiJ6VUZgERHRldLAIiKiK6WBRUREV+q6BibpTEkbL8Hrpkg6dtC6yZLOHbvqIiKiXbqugUVERECXNzBJR0m6XtIsSV8t6yZLulTSD0sg7/GDXrOCpAsk7VZWrSJphqRbJX2t7LOspG9JuqYE+K5X1u9Z8377lXXTJR1X1q9bp8ZFYb5z57byjyMioqd0bQOT9CZgMrC97W2A5SXtUTZvRJWq0Qe8UdKqZf2ywBnAd21fUta9EvgIsCWwg6TVgP2Au23vCBwEHFnWHwzsRBXc+z5JA1mJC21vZ/v+wXUuFuY7ceKYnX9ERK/rxufAlgMWAJsDl9QE6F4JbAzcAfTbng8g6R7gRWWfvYGrbF9cc7x+24+Xfe8GVgO2AF4r6a1ln7nAK4ANgYEpVCYALynLN47d6UVERDO6qoFJEtWo68/AncBewE/L5p2An5fl2nwsAyrLPwJWk3SI7ZPKumcG7QtwDzDb9g/K+64MPB+4HdjdtiWtbHt+VRILx+YMIyKiWV1zCVHSVOAG4EzbT9m+lGo+rtmSZgJ/s33lCIcx8FHg1ZIOa7DfqcDukq6VdCmwle25wAXAbEmXUwX8RkREhyTMt40S5hsRMToJ842IiHEnDSwiIrpSGlhERHSlNLCIiOhKXXUbfadImg68HXiY6pb824Av2P7HqA708Bw4WyPvF71pam6oihiNjMCad7jtKbZ3AGYDMzpdUEREL0sDWwK2zwEWSnqppH0lfaPkJm7T6doiInpFLiEuufuASWV5jZKbOISkacA0gEkT2lNYREQvyAhsyW0K/G9ZHjYLcbEw31XaU1hERC/ICGyUJC1DlUp/l+2/JQsxIqIz0sCad5ykw6nCf38CfGLUR1h9S5iaKKmIiLGQBtYE29OB6cNsO7OdtURERCXfgUVERFdKA4uIiK6UBhYREV0pDSwiIrpSGlhERHSl3IXIGIb1RkRE22QEtkjCeiMiukgaWB2DwnpXkTSjhPXeLGkfgBLie4qkiyTdJemdHS47IqKn5BLi8O6jCuvdA7jc9vclrQjMlPSLss9qtveQ9GLgIqqEjsUsFuY7adLgzRERsYQyAhveQFjv5sDFALafAn4FrFf2ub6sf2i4gywW5jtxYksLjojoJWlgg0haRtKhlLBe4E5gl7JtBeA1wO/L7rVT6GY63YiINkoDW+Q4SVcDlwPzWRTWewzwNknXlm1fsf1oZ0qMiIgBsjNwaJe+vj739yeNPiKiWZLm2O6rty0jsIiI6EppYBER0ZXSwCIioiulgUVERFfKg8zt9PAcOFudriJ60dTcrBXjT0Zgw5D0LkmzJN0g6SZJWzXYd4qkY9tZX0REr8sIrA5J7wLeBrzZ9uNl3QqdrSoiImqlgdV3KPDGgeYFYHuBpGWBrwGvAlYCfmr7uA7VGBHR03IJsb5lbM+rs/6DwEO2pwBvALaVtFmjA0maJqlfUv/cekeMiIglkgZWn4e5ZLg5i4J9nwGuATZqeKDaMN9VxrzOiIielQZW34+AEyQtB6DK81g82HcZYDvg9o5VGRHRw/IdWH0nAYcA10r6N7CQ6nux04BTJF0PPAN83/bdktZq6qirbwlTk4UYETEWEubbRgnzjYgYnYT5RkTEuJMGFhERXSkNLCIiulIaWEREdKU0sIiI6Eo938BGE9rb4BjblpipiIhok55+DmwMQ3uPpnrA+ekxLC8iIhro6QbG8KG9LwS+D7yQapS6l+1HJPUDc4BXAk8A7wEOoIqYulzSdNtX176BpGnANIBJkya1/owiInpETz/ILOkW26+ts34lYHnb8yR9HrjX9g8lPQZsavsBSfsC69r+gqSZwC62n2z0fnmQOSJidBo9yNzrIzBLWsH2gkHrXwYcLGkesDHwt7L+f2w/UJZvpspCjIiIDuj1mziGC+39BDDD9hHA/9Xsv76k1cvybsBvyvLTwIrtKTkiIiAN7CTgPqrQ3pnAFcCGwIXA6ZJ+DtTeXfgX4MSy7+bAqWX9RcB1krZvS9UREdHb34GNlqSbbG+9pK/Pd2AREaOTMN+IiBh3MgJro3JTyN2drqNDJgB/73QRHZTzz/n36vkv7bmva3tivQ29fhdiu9093FB4vJPU36vnDjn/nH/vnn8rzz2XECMioiulgUVERFdKA2uvU0feZdzq5XOHnH/Ov3e17NxzE0dERHSljMAiIqIrpYFFRERXSgNrAUlfknRtmShz05r1L5B0jqTrJF0gadVO1tkqDc5/M0mXS7pe0o+XcO6157zhzr9m+0skzS+zHow7jc5f0n5l4thZknbuVI2t0uDf/gqSzpB0taRLy5RN446kiZL+W9KXBq1vyWdfGtgYk7Qd8BLbOwAfAY6v2XwIcJHt7alyFw/oQIktNcL5G9jD9nbA/cBeHSixpUY4/wFHME4fam10/uUDfTvgDba3sX1Vh8psiRH+7ncB/mx7J+CnwIc7UGI7nAA8BSw/aH1LPvvSwMbem4FzAGz/Fli9ZttOwHll+Xzg9e0trS2GPX/bd9h+qvz6CPD40Jd3vUZ//0jagqqR/7H9pbVFo/P/ENX/uFxdRuATOlBfKzU693nAi8ryBGBue0trD9vvB66rs6kln31pYGPvxSz+j3OhpIE/5xVt/7ss/4NF/6DHk0bnD4CkbYBNgcvaWVibDHv+klYGjgW+0InC2qTR3/+GwN9tT6H6MPt8m2trtUbnfgPwSkl3Ae8Fftbu4jqsJZ99aWBj7zEW/8t5xvYzA8s1/6BfxPj8v7Bhz7/Mt3YE1f+Nvd/2050osMUa/f2fBHzZ9mPtL6ttGp3/QuDSsnwxsEk7C2uDRud+DPAV25sA+9B7z4W15LMvDWzsXQ+8E0DSJsADNdtuZtH3Pu8ArmxvaW3R6Pw/CvzV9pfGafOCYc5f0ouBLYH9JZ1L9eF9ZodqbKVGf/+zgV3L8hTg9rZW1nqNzn1d4MGy/BDVrO+9pCWffXmQeYyV/8s4GXgV1XXvjwAHAkcBqwI/AJ4H3At8vOY7oXFhhPO/AFgNWFB2v9D2ie2vsnUanb/tBTX7zQR2sf1kJ+pslRH+/lcAzgAmUo1WPmj7Hx0qdcyNcO7rAadQDRqWBz5le3aHSm0pSVOo/m0fIenLtPCzLw0sIiK6Ui4hRkREV0oDi4iIrpQGFhERXSkNLCIiulIaWEREdKU0sIiI6EppYBER0ZX+P/7kkGPmyrUYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rc('font',family='Malgun Gothic')\n",
    "titanic_df.groupby('Name')['Survived'].mean().plot(kind='barh',color='orange')\n",
    "plt.title('Name 별 생존율')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bb9976",
   "metadata": {},
   "source": [
    "#### -> insight\n",
    "1. Lady, the Countess , Sir, Ms, Mme, Mlle:1.0\n",
    "2. Mrs Mr Major Dr Col:평균 0.5\n",
    "3. Miss < Mrs -> 기혼 여성의 생존율이 더 높음\n",
    "4. Mr < Ms : 여성의 생존율이 3배 이상 높음\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e34aa237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '성별 기준 생존율 비교')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Sex',y='Survived',data=titanic_df)\n",
    "plt.title('성별 기준 생존율 비교')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a3d8efca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Ticket', ylabel='Survived'>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(25,5))\n",
    "sns.barplot(x='Ticket',y='Survived',data=titanic_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c62e8d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Pclass 기준 생존율 비교')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Pclass',y='Survived',data=titanic_df)\n",
    "plt.title('Pclass 기준 생존율 비교')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1609df1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '세대별 생존율')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAAGACAYAAACXytdHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAiOklEQVR4nO3de5hdVX3/8fcXkhDBgAQCsYSYIEgIoGmJFsRcTCggimDFChYpBQVpy69IIaBSykXRBKS0VIQICpECoqW15SLINUiBEkQEDDcr0IwOJiAYxQgh398fZw+cDDPJJMxeZ+bk/XqePLPP2nuv/T05OSefWWufvSMzkSRJUr3Wa3UBkiRJ6wJDlyRJUgGGLkmSpAIMXZIkSQUYuiS1XERMiIg3rcH24yJi9BpsPzkiRq1VcY39t4iIsWu7vySBoUtSC0XExRHxHuBEYFIftn+8WjwU2LuXdc19T68e/g2wYx/6Pyci9uihj32Aw7pt+52I+FH157GI+HXT4x8199O0zyERcWv1Z35E3Fkd482rq03S4Dek1QVIWndExI3AJzLzidVsdxJwBPBs1fSzzPzQWhzynIh4DpgAXNyH7Tes/qxWZh7QtRwRnwX+H/CezPxNT9tHxBQawe0DzdtExJ8ClwB79uW4kgYvQ5ekgerkzLx4DbYfExELmh6PozEi9gPgvD72MQlYDPxnXw8aEQcC+wGnAldGxEGZ+XwPmz4HvAmYEBE/zMwVEbEZsBPwdF+PJ2nwMnRJKmkj4A019b0oMyd3PYiIi2lMKx4AvAuYu6qdI2IakMCfRcRXM3NRteoCYBiN0aiubUfRmHL8OLAI2CMzl0bEL4BbI+Iq4ObMvKNrn8x8ICKOoDGCt21EDAGeB24CPvG6nrmkQcHQJamIiAhgWxqB4/3A/sB2wIVr2M/+NKYLn+i2auuI+FHT47HAn2bmrVUAW1Wf2wP/DHyYxgjZdyPi4Gr1kVXbuKZd1gPGAEdn5sKI2DEijsrMv4mIa4H3VetXkpn/A/zPap+kpLZk6JJUygzgEeDDmXkocNbqwlAvJgCbd2/MzA1Wsc8twM9Xsf4o4KDMfBx4PCL+GhjZ28aZ+TTwhaamN1CFrMx8Efhu8/YRcVfTw0nAj6rlUTRG0Tqqx+ev4ZSqpEHE0CWplBNojBr9Y0Rsn5mPrE0nmfmliBje07qIuADYpZddH1xFn8dU+weNEbg/BbYCVgD7Av8KXN10nB/1cvzu7f+SmRdm5q4RsSmwPfBt4Jhq/QdphLtzM/Oh3uqT1B4MXZJqFxGfBh7IzIeqb/pdGBH7rGa3fSNiDDAU2Jg+TENm5pG9HP9CYEQfSj2bxujTF4Gf0vgm4+7AN4GPAUuq40yKiK2B7TPzxj70C43z2bYFPlP9BPgJ8EbgImDXPvYjaZAydEmqVXXR051oTOGRmQsi4lxg61XsdgXwQ+BlYBnwG+DJPhzrQnq+3tfWNILT6nwM2Cozl1ePlwH/VV0Y9cPA/U3bbg8cCPQ1dI0HPtVDu5/D0jrCN7ukWmXmc8Dh3dquBGjM5vW4z+PA493be9u+ybbAAau7Dtgq3AP8VUSc1xW8IuIPgD8HTl/LPrtsBizomsqUtO4xdElqN9dGxIs9tP9rZp65mn0/BvwDcGdEdI12vQh8OTOv62H7D0XE5B7aycxJPTR/NCJ6m0bcq5fre0lqE5GZra5B0jouIjYEXmya1lvd9sOBFdU3BSVpUDB0SZIkFeANryVJkgowdEmSJBVg6JIkSSpgwH97cfPNN89x48a1ugxJkqTVuvfee5dk5qie1g340DVu3DgWLFjQ6jIkSZJWKyJ6vZCz04uSJEkFGLokSZIKMHRJkiQVMODP6ZIkSQPLSy+9xKJFi1i2bFmrS2mZ4cOHM2bMGIYOHdrnfQxdkiRpjSxatIgRI0Ywbty4vtyIvu1kJs888wyLFi1i/Pjxfd7P6UVJkrRGli1bxmabbbZOBi6AiGCzzTZb45E+Q5ckSVpj62rg6rI2z9/QJUmSBqSXX36Z4447jpkzZ7Lbbrtx8sknt7qk18VzuiRJ0oD0ve99j/XXX5+bbroJgN///vctruj1caRLkiQNSOPHj+f+++9n8eLFAGywwQbceeedTJ8+nalTp/L5z38egA996EMsXLiQ3/3ud8yYMYOlS5e2suxeOdIlSZIGpIkTJ3LmmWdy1FFHscMOO3DSSSdx3HHHcd1117Hxxhtz4IEH8uSTT3Luuedy7LHHMmHCBE466SRGjBjR6tJ75EiXJEkasHbeeWe+853vsPvuu7P//vvz6KOP8sEPfpDp06fz8MMPs2jRIsaMGcM222zDD3/4Q2bMmNHqknvlSJc0wMyaNYvOzk5Gjx7NnDlzWl2OJLVMZ2cnI0eOZNiwYUyZMoVTTz2VCRMmcMMNNzBs2DBeeOEFNtxwQzo6OvjZz37G2LFjufvuu/njP/7jVpfeI0OXNMB0dnbS0dHR6jIkqeUeeughjjvuODbeeGPWX399TjvtNJYtW8bUqVMZMWIE48eP5/zzz+fII4/kn/7pnxg5ciQf/OAHuf7669lwww1bXf5rGLokSdKANHPmTO67777XtO+7774rPb766qtfWb799ttrr2tteU6XJElSAYYuSZKkAgxdkiRJBRi6JEmSCjB0SZIkFWDokiRJKsBLRkiSpNdll+Pn9Wt/9555SL/212zXXXflrrvuqq3/VXGkS5IkqQBDlyRJGnSeeOIJ9tlnHz75yU+y0047cc0113DwwQfzzne+k2OPPZbnn3+e/fbbj+nTpzN16lR+9atfrbR/Z2cn++23HzNmzOCjH/0oL774Yu01G7okSdKg9NOf/pSvfOUrzJ8/n4MOOojTTz+de+65hxtvvJFhw4Zx6aWXcuuttzJz5kyuvfbalfY9/vjjOeWUU7j55puZNm0a3/rWt2qv13O6JEnSoDRp0iSGDRvGyJEjmTBhAuPHjwdg7NixLFiwgCuuuIIRI0bw8MMPs+WWW660749//GM+/elPA7Bs2TI+8pGP1F6voUuSJA1KEfHK8nrrrTx5N2/ePA477DB22203jj766Nfsu91223HWWWcxbtw4VqxYwUsvvVR7vYYuSZLUdqZOncrhhx/Odtttx1ZbbfWa9WeccQaHHXYYAJtssgnnnXceb37zm2utKTKz1gO8XpMnT84FCxa0ugypmEMOOYSOjg622mor5s3r369hS1J/WLhwITvssEOry2i5nv4eIuLezJzc0/aeSC9JklSAoUuSJKkAQ5ckSVIBhi5JkqQCDF2SJEkFGLokSZIK8DpdkiTpdXnqtJ37tb+xJz+w2m1mz57Nt7/9bc4++2ymTp3aL8c95ZRT2HXXXdl77737pb/uDF2SJGnQufLKK7nnnntecyX6gWzwVCpJkgQcc8wxPPbYY8yYMYPZs2czZcoUdt99d6677joADj30UE499VTe9773sf/++3PVVVexxx57MGnSJBYuXAjAN77xDWbOnMkuu+zC3LlzX3OMuXPnvqbf18vQJUmSBpVzzjmHiRMncsEFF3DPPfcwf/58brnlFmbPnv3KNuPGjeO6665j22235frrr+fGG2/kc5/7HJdccgkAH/jAB7jpppuYP38+X/3qV1fq/5FHHuGGG27osd/Xw+lFtb1Zs2bR2dnJ6NGjmTNnTqvLkST1k/vvv5/777+f9773vQA8/fTTLF++HIB3vetdAGy77bZssMEGAIwfP56bbroJgEsuuYRf/vKXDBkyhGXLlvWp3yFDXl9sMnSp7XV2dtLR0dHqMiRJ/extb3sb06ZN48ILLwTghRdeeCUYRcQr2zUvAzzzzDN8//vf5/rrr+fnP/85l112WZ/7fT2cXpQkSYPSpEmTGDt2LLvttht77bUXF110UZ/2GzlyJBtuuCG7774755xzDltssUW/9Ls6kZn90lFdJk+enAsWLGh1GRrEDjnkEDo6Othqq62YN29eq8tZrcFWr6R1z8KFC9lhhx1aXUbL9fT3EBH3ZubknrZ3elGS+pHnEErqjaFLkvqR5xBK6o3ndEmSJBVQW+iKiNMj4raIuCMidmxqHxYR34iImyPi2ojYpK4aJElSPQb6OeF1W5vnX0voiogpwJaZOQ04EjizafXeQEdmzgCuAj5RRw2SJKkew4cP55lnnllng1dm8swzzzB8+PA12q+uc7r2BC4HyMwHI2Jk07qlwKbV8ubAz2uqQZKkPvNLEH03ZswYFi1axOLFi1tdSssMHz6cMWPGrNE+dYWuLYDmV2J5RKyXmSuAHwB/HxE/AV4G3t1954g4AjgCYOzYsTWVKEnSq/wSRN8NHTqU8ePHt7qMQaeuc7qe59XRLIAVVeACOAM4KzMnAh8HXnOXycycm5mTM3PyqFGjaipRkiSpnLpC1+3AAQARMRFY1LTuLUBntfxLYOuaapAkSRow6ppevAbYJyJup3EO15ERMRv4++rPeRGxHjAUOL6mGiRJkgaMWkJXNZV4VLfmE6qfjwAz6ziuJEnSQOXFUSVJkgowdEmSJBVg6JIkSSrA0CVJklSAoUuSJKkAQ5ckSVIBhi5JkqQCDF2SJEkF1HVFemmd8NRpO/d7n8ufHQkMYfmzT/Z7/2NPfqBf+5Mk9Z0jXZIkSQUYuiRJkgpwelGSNOgMtql9cHpfjnRJkiQVYeiSJEkqwNAlSZJUgKFLkiSpAEOXJElSAYYuSZKkAgxdkiRJBRi6JEmSCjB0SZIkFWDokiRJKsDQJUmSVIChS5IkqQBDlyRJUgGGLkmSpAIMXZIkSQUYuiRJkgowdEmSJBVg6JIkSSrA0CVJklTAkFYXIEnSQLD58BXA8uqn1P8MXZIkAce9/blWl6A25/SiJElSAYYuSZKkApxelLROeuq0nWvpd/mzI4EhLH/2yX4/xtiTH+jX/iSV5UiXJElSAYYuSZKkAgxdkiRJBRi6JEmSCjB0SZIkFWDokiRJKsDQJUmSVIChS5IkqQBDlyRJUgGGLkmSpAK8DZAGjF2On1dLvyOWLGV94KklS/v9GP8+ol+7kyS1MUe6JEmSCjB0SZIkFWDokiRJKsDQJUmSVIChS5IkqQBDlyRJUgGGLkmSpAIMXZIkSQUYuiRJkgowdEmSJBVg6JIkSSrA0CVJklSAoUuSJKkAQ5ckSVIBtYWuiDg9Im6LiDsiYsdu6/4yIu6q1s2sqwZJkqSBYkgdnUbEFGDLzJwWETsBZwL7VOt2BKYA787MFXUcX5IkaaCpa6RrT+BygMx8EBjZtO5w4Eng5oi4MiI2r6kGSZKkAaOu0LUFsLjp8fKI6DrWdsCSzJwOfBv4h+47R8QREbEgIhYsXry4+2pJkqRBp67Q9TywadPjFU1TicuBa6vlq4GJ3XfOzLmZOTkzJ48aNaqmEiVJksqpK3TdDhwAEBETgUVN6+6kOr8LmA78uKYaJEmSBoy6Qtc1wLCIuB04CzghImZHxDDgPGB6RNwKfAr4fE01SJIkDRi1fHuxmko8qlvzCdXPF4GP1HFcSZKkgcqLo0qSJBVg6JIkSSrA0CVJklSAoUuSJKkAQ5ckSVIBhi5JkqQCarlkhKS1t/nwFcDy6qckqV0YuqQB5ri3P9fqEiRJNXB6UZIkqQBDlyRJUgGGLkmSpAI8p0uS+pFfhJDUG0OXJPUjvwghqTdOL0qSJBVg6JIkSSrA0CVJklSAoUuSJKkAQ5ckSVIBhi5JkqQCDF2SJEkFGLokSZIKMHRJkiQVsMor0kfEnUACQ4HNgKeBPwCeyswp9ZcnSZLUHlY50pWZu2Xmu4H7gKmZuRvwJ8A9JYqTJElqF32dXnxrZi4CyMxHgT+sryRJkqT209fQ9WxEHBQRm0TEB4CosyhJkqR209fQdRgwEbgMeB9wcG0VSZIktaFVnkjfJTOXRsTXgK0y886aa5IkSWo7fRrpiojPArOBr0TE8Ig4v96yJEmS2ktfpxf3zMyDgOczcxmwTY01SZIktZ2+hq6MiDdWP4cAI2qsSZIkqe306Zwu4DPA94C3ATcBX6itIkmSpDbU19A1JDPfExGjgCWZmXUWJUmS1G76Or14QETcDBwAbFRjPZIkSW2pT6ErM48B9gQ6gfMi4st1FiVJktRu+jrSBY0bXo8HtgBW1FOOJElSe+rTOV0RcQ3wMnAxsG9mvlRnUZIkSe2mryfSH5GZHbVWIkmS1MZWGboi4tTM/AfgOxHR9Y3FADIz3117dVI/WDFso5V+SpLUCqsb6foiQGbuVqAWqRa/3W7PVpcgSdKqT6SvbvlDRNwZEX8XEZuWKUuSJKm99PXbi1OAnwLnR8TXIuJdNdYkSZLUdvp6na7lmfkfwN8AvwAuq7MoSZKkdtOn0BURB0bEfwIXAPcCE2qtSpIkqc309ZIR44EjM/MXdRYjSZLUrvp6TtdbDVySJElrr6+h6+mI2L7WSiRJktpYX6cXZwB/FhG/onE7IC+OKkmStAb6FLq8OKokSdLr09cbXh/SvS0z5/V/OZIkSe2pr+d0vaHpz87A3rVVJEmS1Ib6Or14QfPjiPhcPeVIkiS1p76OdL0iIjYA3l5DLZIkSW2rr+d03Qlk9fBl4KzaKpIkSWpDqxzpiohTImJo9e3F6cATwPrAb+ovTZIkqX2sbnrxTzLzpWr5c8DFwB7AZ+osSpIkqd2sLnT9DiAiNgcmZuYNmfkCjdEuSZIk9dHqzum6LyK+CLwDOB4gIoYCm9RdmCRJUjtZXeg6gcY1ueZl5sKqbSRwXK1VSZIktZlVhq7MXAFc263taeDpOouSJElqN2t8nS5JkiStudpCV0ScHhG3RcQdEbFjD+u3jIgXImJ4XTVIkiQNFLWEroiYAmyZmdOAI4Eze9jsRGBJHceXJEkaaOoa6doTuBwgMx+kcfL9KyLij2hc4f5/e9o5Io6IiAURsWDx4sU1lShJklROXaFrC6A5LS2PiPUAImJD4EvAqb3tnJlzM3NyZk4eNWpUTSVKkiSVU1foeh7YtOnxiuqbkAD/CMzOzOdrOrYkSdKAU1fouh04ACAiJgKLquUtgF2AT0bEFcBEGrcWkiRJamuruzjq2roG2CcibgeWAkdGxGzg7zNzctdGEXErcGhNNUiSJA0YtYSuairxqG7NJ/Sw3fQ6ji9JkjTQeHFUSZKkAgxdkiRJBdR1TpckSRqkZs2aRWdnJ6NHj2bOnDmtLqdtGLokSdJKOjs76ejoaHUZbcfpRUmSpAIMXZIkSQUYuiRJkgowdEmSJBVg6JIkSSrA0CVJklSAoUuSJKkAQ5ckSVIBhi5JkqQCDF2SJEkFGLokSZIKMHRJkiQVYOiSJEkqwNAlSZJUgKFLkiSpAEOXJElSAYYuSZKkAgxdkiRJBRi6JEmSCjB0SZIkFWDokiRJKsDQJUmSVIChS5IkqQBDlyRJUgGGLkmSpAIMXZIkSQUYuiRJkgowdEmSJBVg6JIkSSrA0CVJklSAoUuSJKkAQ5ckSVIBhi5JkqQCDF2SJEkFGLokSZIKMHRJkiQVYOiSJEkqwNAlSZJUwJBWFyBJvZk1axadnZ2MHj2aOXPmtLocSXpdDF2SBqzOzk46OjpaXYYk9QunFyVJkgowdEmSJBVg6JIkSSrA0CVJklSAoUuSJKkAQ5ckSVIBhi5JkqQCDF2SJEkFGLokSZIKMHRJkiQVYOiSJEkqwNAlSZJUgKFLkiSpAEOXJElSAYYuSZKkAoa0ugBJUnuaNWsWnZ2djB49mjlz5rS6HKnlagtdEXE6MLU6xhGZ+VDV/nbgLOANwC+AgzPzxbrqkCS1RmdnJx0dHa0uQxowaplejIgpwJaZOQ04EjizaXUC+2bmFOBJYL86apAkSRpI6hrp2hO4HCAzH4yIkV0rMvOBpu1+Bfy2phokSZIGjLpOpN8CWNz0eHlErHSsiNgd2BG4vvvOEXFERCyIiAWLFy/uvlqSJGnQqSt0PQ9s2vR4RWauAIiGE4EZwCGZ+XL3nTNzbmZOzszJo0aNqqlESZKkcuoKXbcDBwBExERgUdO6TwG/yMzTewpckiRJ7aiu0HUNMCwibqfxTcUTImJ2RAwD9gWOjIhbqz/H1lSDJEnSgFHLifTVVOJR3ZpPqH7uU8cxJUmSBjKvSC9JklSAoUuSJKkAQ5ckSVIBhi5JkqQCDF2SJEkF1HbDa0nS4LDL8fNq6XfEkqWsDzy1ZGm/H+PfR/Rrd1IRjnRJkiQV4EiXpH5Rx2iJIyWS2okjXZIkSQUYuiRJkgowdEmSJBVg6JIkSSrA0CVJklSAoUuSJKkAQ5ckSVIBhi5JkqQCDF2SJEkFGLokSZIK8DZAkqRarBi20Uo/pXWdoUuSVIvfbrdnq0uQBhSnFyVJkgpwpEuSpEFsl+Pn9XufI5YsZX3gqSVLa+n/3jMP6fc+BwNHuiRJkgowdEmSJBVg6JIkSSrA0CVJklSAoUuSJKkAQ5ckSVIBhi5JkqQCDF2SJEkFGLokSZIKMHRJkiQVYOiSJEkqwNAlSZJUgDe8ljRgrRi20Uo/JWkwM3RJGrB+u92erS5BkvqN04uSJEkFGLokSZIKMHRJkiQVYOiSJEkqwNAlSZJUgKFLkiSpAEOXJElSAYYuSZKkAgxdkiRJBRi6JEmSCjB0SZIkFWDokiRJKsDQJUmSVIChS5IkqQBDlyRJUgGGLkmSpAIMXZIkSQUYuiRJkgowdEmSJBVg6JIkSSrA0CVJklSAoUuSJKkAQ5ckSVIBhi5JkqQCDF2SJEkF1Ba6IuL0iLgtIu6IiB2b2t8YEZdHxPyI+I+I2LiuGiRJkgaKWkJXREwBtszMacCRwJlNqz8N/FdmTgW+DxxVRw2SJEkDSV0jXXsClwNk5oPAyKZ1M4BvV8v/BuxWUw2SJEkDRmRm/3cacQFwbhW4iIgfAFMzc0VE/HdmvrtqHwrcWI2INe9/BHBE9XB74JF+L3Lg2BxY0uoitNZ8/QYvX7vBzddvcGvn1+8tmTmqpxVDajrg88CmTY9XZOaKruWIWK96vCmwuPvOmTkXmFtTbQNKRCzIzMmtrkNrx9dv8PK1G9x8/Qa3dfX1q2t68XbgAICImAgsalp3N7Bftfxh4MaaapAkSRow6gpd1wDDIuJ24CzghIiYHRHDgC8CR0TErcAuwDdqqkGSJGnAqGV6sZo67P6txBOqn0uA99Vx3EFqnZhGbWO+foOXr93g5us3uK2Tr18tJ9JLkiRpZV6RXpIkqQBDV40i4tCI+FSr69Cai4hfR8StEXHv6l7DiLirVF3qXUS8NSLGrOE+a/XaRcT0tdlPr09fPlO7XtOI2CQiJhUpTK+oPjeH97W9lz6mR8SX+r+61jN0ST37SWZOB96Fd00YLD4O7FToWG35H0Kb+UPgwFYXoTUTEdHqGupk6FpD3RN4RNxVtV0aEVdFxAMR8bfd9tkkIm6OiMm9bRsRI6r2WyLi7oj4eEQMi4g7qvXDI2JJRGwUDbdV7Qsi4vyqjstL/l2sI94MdMArr+N3q9/Y5kdE17Xo1o+Ir1ZtN0TEyIg4r2s0JCI2joibWlN++4qIbav3y+0RcR9wKDAnIo7tPiLSNPqxcUR8p9rva8DQqv2NEXFZ9T69OiJGVu2veX9FxLnAxOrfwcTCT7vtRcQV1etzV0RsExEHVJ+J1wN7NG13V9Pyl5pHHyNiK+Ac4GMRMa9c9eueiDglGvdZnh8RuzS1D4mIi6p1VwAbV+1dn5e3RMRNETG+ar8rIr4IXNTUx59FxClNj2/oem8OVoau/vMW4CPAZKB5+HtD4DLghMxcsIptTwRuyMz3AlOBv6Lxj/T/ImJrGrdWuhuYSeNSG3dW+20LnJyZuwIbRcTO9Ty9dc7EiJgP3At8t2r7PXBwNQJ2E7BP1f424AvV/UQvA44G/hk4rFp/CPD1QnWvS94PXJqZU2i8Jy4GZmXm2avYZxbw79X77DRgs6r9RODKzJwBnAf8ddX+mvdXZh5NNRKamT/p92elo6vX56vAQcCxwPTM3IvGhbdXKzM7gGOAyzLzkLoKXddFxB7Am6q7yuwPnNq0+lDgf5vuwTy6av9L4JHqNT4aOKlq3xz4ZmYe1tTHVcAeEbFeROwEPJGZz9b1fEqo64r07ay3r3v+d2a+DLwcEb9uav9/wEWZec9qtp0EfBkgM38fEf8DjKfxH/7eNIbK/5bGB1AHrwaBRzLzl9XyQla+z6XW3k8yc2pEDAG+HhEP0Lh7wjERsRSYADxdbftwZnZdAPhuYEpmPlyNqryJxsWA31+4/nXB14BjI+LsarlZb+/TP+LV99n/RcTTTe3TIuIYGp+LXe9X318FRcQWwMkR8RvgD4AxwD2Z+btqkwXABq2qT6/xR8DMaFx3E2B94OWmdV8DyMznI+KxpvZ3RsT+1eOuu9I81/2XmMxcHhHX0hjh3Bf4lzqeREmOdK25Z2h8GHTdO/ItVXvzh3zz8tnALhHxkV7Wdy0/RCNcEY2LyL4DeIzGhWb3BIZl5uPAFtW6u3vpq63nw0vLzOXAc8BGNAL0pZl5IvB/TZu9tWnI+/3Aj6rlC2mMeN2RmS8WKXjdkpn5eeAUGiOJL/Pqf8jN79NNeXVE60ngPVX727q2AR4FPluNXr0H+GzXMZqPx6vvL39hrcfHabxfTgTuBx4HJle//ABMb9p2aNPytj301fzvQfV4lMYI8fRqBmCvpnXN77VRvHq+5aPAPzft8xdV+/JejjEXOBzYOjN/3L/ll+cHxxrKzAcj4qWIOAv4Nasf7n4R+ChwVUQE8MtetjsD+FpEHEnjw/2szHwOGudzAf9ZbfdjYHTTvSxVj4nVb2/r0wi4Xberuqj6ja2jadtFwFkRsU21fHjVfg2NqapZRSpe93wsIj5BY9r3EuAB4BvR+AbjhcChEXEG8Bsa71VovM8ujYjjgB8CTzW1XxwRp1XbfwZ4cBXHnl+NRn88Mx/p5+e1LruRxuvz58DDwLM0ppjuiYhOGr+Idvl6RFwC/JTGL0XdPQB8JSK+3m3KSv3nu8DeEfEDYCkr32HmfODyiPgojfDcNYo1l8b79BPAb4EzgVt6O0BmLomI9YC2ODfPi6NKNYmIXYGjMvMvVruxJOk1ImIT4HvAe6rTcgY1R7qkGkTEZ2jc7sqvrEvSWoiIvYHTaXwRbdAHLnCkS5IkqQhPpJckSSrA0CVJklSAoUuSJKkAQ5ekQSsiPhwRj1dfKS953HdUF76VpD4zdEkazA7m1QsIl/RpXr2tiST1iaFL0qAUEWNpXJDxbKoL0kbE1tVNcW+MiDOabnQ9Oho3K785Ir5V3fWhpz5nVjfovS0i/q5q634D5sNp3D1iXkR8rMiTldQWvGSEpEEpIk4BbsvMWyLiGhrB68vAeZl5R0S8Ezg3M3eNiG8CZ2fmfRHxV8DSzPxmt/5G0Lgi+p7VveLWy8wVETEqMxdHxF8AYzLzCxFxMfClzHy44FOWNMh5cVRJg051DtdHgD+MiL8FRgF/CWyTmXdUm93btMvbgX9s3ImL4cC3e+h2e+DuzHweoApc3W/A/PM6no+kdYOhS9JgtBeNG+2eCq/cJP4HwDMR8Y7MvB+Y0bT9Y8BxmflEFdiGvqbHxg16d42IN2Tm76ob2nfdgPnyarpxVLWtN1OWtMY8p0vSYPRJmkarMvNFYAGNe7R9LSJuAXYFllWbfJbGDZJvBv4NGNm9w8xcDJwD3FZtdxiN6cbPRsTVwJubNr8OuCIiDujn5yWpjXlOl6S2ERFDM/OlavlDwLTMPKa1VUlSg9OLktrJgdW3CwGeBY7obcOIuLVb099l5r09bStJ/cGRLkmSpAI8p0uSJKkAQ5ckSVIBhi5JkqQCDF2SJEkFGLokSZIKMHRJkiQV8P8Bm3uA2375nf4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#입력 값에 따라서 구분값을 반환하는 함수를 설정한다.\n",
    "def function1(age):\n",
    "    cat=''\n",
    "    if age<=0:\n",
    "        cat='unknown'\n",
    "    elif age<=5: \n",
    "        cat='Baby'\n",
    "    elif age <=19:\n",
    "        cat='student'\n",
    "    elif age<=65:\n",
    "        cat='adult'\n",
    "    else:\n",
    "        cat='elderly'\n",
    "        \n",
    "    return cat\n",
    "#막대 그래프의 크기를 지정한다.\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "#x축의 값을 순차적으로 표시한다.: 함수에 주어진 값이랑 x_label이랑 같아야한다.\n",
    "x_label=['unknown','Baby','student','adult','elderly']\n",
    "\n",
    "#위에 지정하였던 함수를 반환한다.\n",
    "titanic_df['Age_cat']=titanic_df['Age'].apply(lambda x: function1(x))\n",
    "#그래프 그리기\n",
    "#x축의 값 option:order\n",
    "sns.barplot(x='Age_cat',y='Survived',hue='Sex',data=titanic_df,order=x_label)\n",
    "#삭제하기\n",
    "plt.title('세대별 생존율')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cedc149",
   "metadata": {},
   "source": [
    "##### 노인 여성은 아무도 생존하지 않은 것일까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fcc70385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male    11\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "titanic_df[titanic_df['Age']>=65]['Sex'].value_counts()\n",
    "\n",
    "# male: 1, femaie:2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011f312a",
   "metadata": {},
   "source": [
    "##### -> female은 없는 것을 보아 여성 노인의 생존율이 없는 것이 아니라, 여성 노인이 배에 탑승하지 않아 위처럼 집계된것으로 보임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "df25d0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          891 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        891 non-null    object \n",
      " 11  Embarked     891 non-null    object \n",
      " 12  Age_cat      891 non-null    object \n",
      "dtypes: float64(2), int64(5), object(6)\n",
      "memory usage: 90.6+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ee32c1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STONO</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>female</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NAN</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NAN</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Rev</td>\n",
       "      <td>male</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NAN</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss</td>\n",
       "      <td>female</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NAN</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B</td>\n",
       "      <td>S</td>\n",
       "      <td>student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss</td>\n",
       "      <td>female</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>WC</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>male</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NAN</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr</td>\n",
       "      <td>male</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NAN</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>N</td>\n",
       "      <td>Q</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass   Name     Sex        Age  SibSp  Parch  \\\n",
       "0              1         0       3     Mr    male  22.000000      1      0   \n",
       "1              2         1       1    Mrs  female  38.000000      1      0   \n",
       "2              3         1       3   Miss  female  26.000000      0      0   \n",
       "3              4         1       1    Mrs  female  35.000000      1      0   \n",
       "4              5         0       3     Mr    male  35.000000      0      0   \n",
       "..           ...       ...     ...    ...     ...        ...    ...    ...   \n",
       "886          887         0       2    Rev    male  27.000000      0      0   \n",
       "887          888         1       1   Miss  female  19.000000      0      0   \n",
       "888          889         0       3   Miss  female  29.699118      1      2   \n",
       "889          890         1       1     Mr    male  26.000000      0      0   \n",
       "890          891         0       3     Mr    male  32.000000      0      0   \n",
       "\n",
       "    Ticket     Fare Cabin Embarked  Age_cat  \n",
       "0        A   7.2500     N        S    adult  \n",
       "1       PC  71.2833     C        C    adult  \n",
       "2    STONO   7.9250     N        S    adult  \n",
       "3      NAN  53.1000     C        S    adult  \n",
       "4      NAN   8.0500     N        S    adult  \n",
       "..     ...      ...   ...      ...      ...  \n",
       "886    NAN  13.0000     N        S    adult  \n",
       "887    NAN  30.0000     B        S  student  \n",
       "888     WC  23.4500     N        S    adult  \n",
       "889    NAN  30.0000     C        C    adult  \n",
       "890    NAN   7.7500     N        Q    adult  \n",
       "\n",
       "[891 rows x 13 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4963b15f",
   "metadata": {},
   "source": [
    "### 라벨인코딩[type이 object인 것을 변환하자]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "aaf034ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Name  Sex   Age  SibSp  Parch  Ticket  \\\n",
       "0            1         0       3    11    1  22.0      1      0       0   \n",
       "1            2         1       1    12    0  38.0      1      0      10   \n",
       "2            3         1       3     8    0  26.0      0      0      26   \n",
       "3            4         1       1    12    0  35.0      1      0       9   \n",
       "4            5         0       3    11    1  35.0      0      0       9   \n",
       "\n",
       "      Fare  Cabin  Embarked Age_cat  \n",
       "0   7.2500      7         3   adult  \n",
       "1  71.2833      2         0   adult  \n",
       "2   7.9250      7         3   adult  \n",
       "3  53.1000      2         3   adult  \n",
       "4   8.0500      7         3   adult  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터 전처리: 레이블 인코딩 진행하기 : 0~ 숫자값으로 변환하기\n",
    "\n",
    "#불연속형변수:Cabin Embarked Sex  Name\n",
    "from sklearn import preprocessing\n",
    "def encode_features(dataDF):\n",
    "    #기존에 대해 Ticket Name을 추가\n",
    "    features=['Cabin','Embarked','Sex','Name','Ticket']\n",
    "    for i in features:\n",
    "        le=preprocessing.LabelEncoder()\n",
    "        le=le.fit(dataDF[i])\n",
    "        dataDF[i]=le.transform(dataDF[i])\n",
    "    return dataDF\n",
    "\n",
    "titanic_df=encode_features(titanic_df)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "124e3f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    int32  \n",
      " 4   Sex          891 non-null    int32  \n",
      " 5   Age          891 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    int32  \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        891 non-null    int32  \n",
      " 11  Embarked     891 non-null    int32  \n",
      " 12  Age_cat      891 non-null    object \n",
      "dtypes: float64(2), int32(5), int64(5), object(1)\n",
      "memory usage: 73.2+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_df.info()\n",
    "\n",
    "titanic_df.drop(columns=['Age_cat','Name'],inplace=True)\n",
    "#label encoing: name, age_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227b4544",
   "metadata": {},
   "source": [
    "### 이상치: \n",
    "\n",
    "연속형 변수에 한하여 이상치를 파악하고 제거\n",
    "\n",
    "연속형 변수:Ticket, Age, Fare(요금),Cabin ,Embarked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1d71f4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIIAAABeCAYAAADv/8ypAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAFIklEQVR4nO3dz2scZRzH8fdXm7hQSowmkZBD0sRD0UApBkREbUEllx4qof+ApCWnnjz00h4a6EEQctBDWrwa/HHxYi+2VVEQEooYMR661pgQZDWwSGCTLvvtIbMxm7SddXdmZzL7eUFgn2F59rvJZ595Ms/sjLk7Ik8kXYCkg4IggIIgAQVBAAVBAgqCAHCoFS/S09PjQ0NDrXipWBQKBYrFIl1dXfT29iZdTlMWFhb+dvd9b6IlQRgaGmJ+fr4VLxW59fV1Jicn2draorOzk+vXr9Pd3Z10WQ0zsz8etl27hhBzc3NUKhUAKpUKc3NzCVcUDwUhxO3btymXywCUy2Vu3bqVcEXxUBBCnDx5EjMDwMw4depUwhXFQ0EIMT4+TnU9xt0ZHx9PuKJ4KAghbty48dh2VigIIfbOCW7evJlQJfFSEEK0yzK9ghBic3Ozpl0qlRKqJF4KggAKQqhcLvfYdlYoCCF6enpq2n19fQlVEi8FIcTKykpNe3l5OaFK4qUgCKAgSEBBEEBBkICCIICCIAEFQYAWnbOYhGvXrpHP52Pp++LFi033MTw8zOTkZATVRKOuIJjZz8A/QXMWWAA+AnLAD+7+XjzlSavUOyL85e5vVhtm9hXwrrvfM7PPzOxld/8xnhIbE9Wn7c6dO1y6dGmnPT09zfHjxyPpO03qnSNUqg/M7BCQc/d7waYvgFciris1Tpw4sfO4o6MjkyGAOoJgZoeBETP71sw+Bfr5bzdB8Hjfif5mds7M5s1svlAoRFZwEgYHBwG4fPlywpXEJ3TX4O4bwAiAmb0FfAA8vesp3cC+v7S7z7I9n2BsbOxAn+Zz5MgRRkdHMzsaQH0jwpO7mgXAgafMbCDY9g7wdQy1SQvVM1l83sw+BraCnyngWeBzM9sEvnT3X2OsUVqgnl3Db8CrezbnyfAEsR3pyKIACoIEFAQBFAQJKAgCpGj1Mc7VwmZV64pi1TEuza5mpiYI+Xyeu3d/YmAgfV8p6+joBKBUStW62o7V1ea/dJOaIAAMDJS4cOH3pMs4cGZmjjbdh+YIAqRoRFhbW2NjIxdJutvNykqOw4fXmupDI4IAKRoR+vv7KZWWNUdowMzMUXK5/qb60IgggIIggdTsGmD7/+E0ThYLhe3jCL29WwlX8nCrqzlGRprrIzVBGB4eTrqER7p/f/vIYi6XzhpHRpr//aUmCGn6ssde1UPLV69eTbiS+GiOIICCIAEFQQAFQQIKggAKggQUBAEUBAkoCAIoCHVZWlpicXGRqamppEuJjYJQh+pd3vZelzlLGl5rMLMrwOtBH+fc/ZfIqopAVKfHLy0t1bTPnDnDsWPHmu43bRfTamhEMLPXgOfc/Q3gPPB+pFWlSHU0eFQ7KxodEd4GPgFw90Uzeya6kqIR1aft9OnT+7ZlcRWy0TlCH7WXyymbWU1fWbqGUjtoNAhFai+gVXH3yu4nuPusu4+5+9hBv8N6O2g0CN8BEwBm9gKQ2en0xMRETfvs2bMJVRIva+S+hsFu4ENgFPgXOO/ufz7m+QXgoberPwi6urpeqj4uFosLSdYSgUF33zdENxSEdmRm8+4+lnQdcdEBJQEUBAkoCPWbTbqAOGmOIIBGBAkoCHUwsytm9o2ZfW9mLyZdTxwUhBDtssCmIISrWWADUrfAFgUFIVzoAlsWZO4NxSB0gS0LFIRwbbHApuMIIf7vAttBpSAIoF2DBBQEARQECSgIAigIElAQBFAQJKAgCAAPAFljZ7emB5miAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIIAAABeCAYAAADv/8ypAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAEN0lEQVR4nO3dz0tsZRzH8fd3ULum4L2h+RMaXFbkooFocWkjEZQLo32LMPeX2rrJhd5oWcT1D2hRIbQ2KKIgGHETtJObhqBmISly/THfFj6FZxx8pnHOHD3zea38nhlnvoMfnnPmPM85mrsjUsi6AbkZFAQBFAQJFAQBFAQJFAQBoKMVb9Lf3+/FYrEVb5WK9fV1KpUKhUKB8fHxrNu5ltXV1T/cfaB6e0uCUCwWKZfLrXirpltbW2Nubu6/en5+nomJiQw7uh4z+63Wdu0aIhYXFxP1wsJCRp2kS0GIODw8TNQHBwcZdZIuBUEABUECBUEABUECBUEABUECBUEABUECBUEABUECBUEABUECBSHCzK6s80JBiKi+7iOv14FEF6aY2V3gc2CI8+C8C3QBnwF3gJ/c/cMUe8xUR0cHp6eniTqP6vlUTwMP3H3LzN4EPgDGgffc/bGZfWlmr7j7z6l2mpGzs7Mr67yI7hrcfcvdt0L5F/AEuOPuj8O2r4FX02kve+2ya6j7GMHMRjkfDT4B9i48tAfcq/H8982sbGbl3d3dazcq6aorCGb2FjAHzAB/AncvPHwPuPSXdvdH7l5y99LAwKVFs3LDRINgZi8BU+4+6+577n4EPBVGCIC3gW/TbFLSV8/B4hvAfTP7LtQbwAPgKzN7Anzj7r+m1J+0SDQI7v4QeFjjodweILYjnVASQEGIKhQKV9Z5kc9P1USjo6OJemxsLKNO0qUgROzs7CTq7e3tjDpJl4IQUT230NnZmVEn6VIQInTtowDQ09OTqHt7ezPqJF0KQsTJyUmiPj4+zqiTdCkIEYODg4l6aGgoo07SpSBE6FuDAPrWIIG+NQigVcwSaKmatBUFQYAW3XCzHktLS6ysrDTt9Y6OjlIbxqempq79GmZGd3d3E7o5Nzk5yczMTMO/rxFBALBWHPyUSiW/rbfgnZ6evnSl0/LycoYdXY+Zrbp7qXq7RoSIiyGoVeeFghCh8wgC6DyCtBkFQQAFQQIFIaJ6GjqvN8pQECKGh4cT9cjISEadpEtBiNjc3EzUGxsbGXWSLgVBAAVBAgVBAAVBgoaDYGYfmdn3Zvajmb3QzKak9RoKgpndBwbd/TVgFvi4qV1JyzU6IrwOfAHg7r8AzzStI8lEo0F4luQt9U7NLPFaus/i7dJoEPZJ3mSz4u6Vi0/QfRZvl0aD8APwDoCZPQ/83rSObpiurq4r67xoaM1i2A18CrwI/A3MuvvmFc/fBWr+u/rboK+v7+V/f97f31/NspcmeM7dLw3RLVm8mgdmVq616DMvdEJJAAVBAgWhfo+ybiBNOkYQQCOCBApCHdphgk1BiGiXCTYFIa4tJtgUhLjoBFse5O4DpSA6wZYHCkJcW0yw6TxCxP+dYLutFAQBtGuQQEEQQEGQQEEQQEGQQEEQQEGQQEEQAP4BayxCMV9sIwQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAH0AAABeCAYAAAAOuBu9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAEX0lEQVR4nO3dP0hzVxgG8OdNgyAdgkGrS2nwc6p1akZrFUO36NIhdE8/Oom4iGsXoYhTl0/p2tBNXQVtardksm4i1OpQUoRQiiAhb4fPlHPz5V81x5Oc8/wg4Ev08saHc29yz70noqqgsMRcN0Avj6EHiKEHiKEHiKEHiKEHKN7vDY6Pj2sqler3Zl9MpVJBtVpFIpHAxMSE63aerFwu/6WqLV9A30NPpVIolUr93uyLuLu7Qz6fx8PDA0ZGRrC/v4+xsTHXbT2JiPze7jnu3g2FQgH1eh0AUK/XUSgUHHdkB0M3nJ6eolarAQBqtRpOTk4cd2QHQzcsLi4iHn97xIvH41haWnLckR0M3ZDL5RCLvf2XxGIx5HI5xx3ZwdANyWQSy8vLEBFkMpmhfRPXTd/fvQ+7XC6H6+trb0c5wNDfkUwmsb297boNq5yEvre3h+Pj475s6/7+HoN+TYCIYHR0tC/bymQyyOfzz9oGj+kBkn6PknQ6rcN6Rs4nIlJW1XSr5zjSA8TQmxSLRWSzWZydnbluxRqG3mR3dxcAsLOz47gTexi6oVgsRs69+zraGbqhMcobfB3tDN3QGOXtal8wdENjhq1d7QuGblhfX4/UGxsbjjqxi6EbFhYWIvPp8/Pzjjuyo6fQReRcRE4fH1/ZbsqlyclJAMDU1JTjTuzp9aD1p6pmrHYyIG5vbwEANzc3jjuxp9fde91qFwNic3MzUm9tbTnqxK6uoYvI+wBeiUhRRH4SkQ9foC8nLi4uIvX5+bmjTuzqGrqq/qOqr1R1AcAegHfOWIjI1yJSEpFSpVKx0Sf1US8j/T2jbJmoqr5R1bSqpof5rpBQ9PJGbkZEfgDw8Pj4xm5L7szOzkZ28XNzcw67sYcXUTTJZrP//Xx0dOSwk+fhRRQUwdANq6urHWtfMHRD4+bFdrUvGHqAGHqAGLqhcfNiu9oXfr6qJzo4OOhY+4KhB4ihG1ZWVjrWvmDohuazk4N+Y+RTMfQAMfQAMXSDiHSsfcHQDYeHhx1rXzD0ADF0gzmX3qr2BUMPEEMPEEMPEEMPEEM3NF8IOcwXRnbC0APE0APE0A38nE7eYugBYugBYugBYugGfk43iMi3IvKziPwqIrO2myK7elmU4DMAk6r6OYDXAL6z3pUja2trkbp5XTlf9DLSvwDwIwCo6m8AklY7cujq6ipSX15eOurErl5C/wDRZUdqIhL5O645M1x6Cb0KwPyCsrqqRu7h5Zozw6WX0H8B8CUAiMjHALxdVW96ejpSz8zMOOrErq5rzjzuyr8H8AmAvwG8VtU/Ovx+BUDbr3EedIlE4tPGz9Vqteyyl2f6qN33p/d9oSEfiEip3SI9PuDJmQAx9AAx9NbeuG7AJh7TA8SRHiCG3iSEySWGbghlcomhRwUxucTQo7pOLvnAuxf0TF0nl3zA0KOCmFzi53TD/51cGlYMPUDcvQeIoQeIoQeIoQeIoQeIoQeIoQeIoQfoXyaITcuREfFBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAH0AAABeCAYAAAAOuBu9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAADn0lEQVR4nO3dv08bdxzG8eexKst0IVQ4BVUixmxtlaVeUTNFHeqtczZgqWSp6kLXDqh08tAF/oB05x/ID2Wzt8xEpaVCcqLoVCFRg/zpAFR2a/Ch+359tj/Pa/LJ5ssH3jpjuONMM4P4Ush7ABk/RXdI0R1SdIcU3SFFd+iD0AsuLi5apVIJvazcUbvdfmtm5WH3BY9eqVTQarVCLyt3RPK3m+4LHj2NRqOBk5OTIGt1u130er0ga8VSKBRQLBaDrLW0tIRms5lpjVyiJ0mCs7NTFIvZY5kRZgwwVTxmF+j1/s68TrdbQJIkmdfJJfry8jIWFo7QaLzJ49NPrWZzFaXScuZ19OrdIUV3SNEdUnSHFN0hRXdI0R1SdIcU3SFFd0jRHVJ0hxTdIUV3aGR0kvdI/kryGckXJFfHMZjEk2ZP/xDAd2b2CMBPAL6POpFEN/IkCjP7s2/zPYDTEJ/4+LiEZnPynjQ6ncvTmsrlbs6T/N/xcQlra9nXSX3mDMlPcLmXfzvkvk0AmwCwsrIycq1qtZp+wjE7Pz8EAJRKkzfj2lqY7x3T/Ncqya8B1AH8YGbvbntsrVazaT4bdnt7GwCws7OT8yTZkGybWW3YfSP3dJIPAdTNbCv4ZJKLNE/vXwFYJ/nsavvIzJ7EG0liS/NCbhfA7hhmkTHRH2ccUnSHFN0hRXdI0R1SdIcU3SFFd0jRHVJ0hxTdIUV3SNEdUnSHcrnQUEj7+/s4PDwMtt71Wtdn0IRQrVaxsbERbL2spj56aHNzc3mPEN3UR5+kPWha6Ge6Q4rukKI7pOgOKbpDiu6Qojuk6A4pukOK7pCiO6ToDim6Q1N/lC20er3+7+2Dg4McJ4kn1Z5O8keSz0m+IvlZ7KEkrjTXkVsH8LGZfQlgC8DP0afKSf9ePmx7VqTZ0x8DeAoAZvYawEdRJ5Lo0kS/D6DTt31BcuDjSG6SbJFsdTodyGRLEz0BsNC33TOzgffLNLM9M6uZWa1cHvpGvjJB0kR/CeAbACD5KYA/ok4k0Y28eODVU/kvAD4H8BeALTP7/ZbHdwDc+DbOk25+fv6L69tJkrTznCWjBze9f3qqK0Z6Q7J109UWZ4H+IueQojuk6MPt5T1ATPqZ7pD2dIcU/T88HFxS9D5eDi4p+iAXB5cUfdDIg0uzYOa+oIxGHlyaBYo+yMXBJf2e3ueuB5emlaI7pKd3hxTdIUV3SNEdUnSHFN0hRXdI0R36ByF95EuOOFTlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(331)\n",
    "sns.boxplot(data=titanic_df['Age'],color='yellow')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(333)\n",
    "sns.boxplot(data=titanic_df['Ticket'],color='yellow')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(335)\n",
    "sns.boxplot(data=titanic_df['Fare'],color='yellow')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(337)\n",
    "sns.boxplot(data=titanic_df['Cabin'],color='yellow')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.subplot(339)\n",
    "sns.boxplot(data=titanic_df['Embarked'],color='yellow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "94beb05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>259</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>680</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>738</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch  Ticket      Fare  \\\n",
       "258          259         1       1    0  35.0      0      0      10  512.3292   \n",
       "679          680         1       1    1  36.0      0      1      10  512.3292   \n",
       "737          738         1       1    1  35.0      0      0      10  512.3292   \n",
       "\n",
       "     Cabin  Embarked  \n",
       "258      7         0  \n",
       "679      1         0  \n",
       "737      1         0  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "titanic_df[titanic_df['Fare']>300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5c08ef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#삭제하기(Fare d이 300이하)\n",
    "\n",
    "titanic_df=titanic_df[titanic_df['Fare']<=300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5c5426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ae2855df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(621, 10) (267, 10) (621,) (267,)\n"
     ]
    }
   ],
   "source": [
    "##별도의 테스트 데이터 세트를 추출하기\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_titanic_df=titanic_df.drop('Survived',axis=1)\n",
    "y_titanic_df=titanic_df['Survived']\n",
    "X_train, x_test, Y_train, y_test=train_test_split(X_titanic_df, y_titanic_df, test_size=0.3, random_state=11)\n",
    "print(X_train.shape,x_test.shape,Y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8e72c93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496, 10) (125, 10) (496,) (125,)\n"
     ]
    }
   ],
   "source": [
    "#train set 을 train/ validation set 으로 분리하기\n",
    "\n",
    "x_train, x_val, y_train, y_val=train_test_split(X_train,Y_train,test_size=0.2, stratify=Y_train,random_state=1)\n",
    "print(x_train.shape,x_val.shape,y_train.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "867f349c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496, 10) (496,)\n",
      "(267, 10) (267,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c0c3613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier #의사결정나무\n",
    "from sklearn.ensemble import RandomForestClassifier #랜덤포레스트\n",
    "from sklearn.linear_model import LogisticRegression #로지스틱회귀\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score #정확도산출\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import Ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3c8df6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 888 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  888 non-null    int64  \n",
      " 1   Survived     888 non-null    int64  \n",
      " 2   Pclass       888 non-null    int64  \n",
      " 3   Sex          888 non-null    int32  \n",
      " 4   Age          888 non-null    float64\n",
      " 5   SibSp        888 non-null    int64  \n",
      " 6   Parch        888 non-null    int64  \n",
      " 7   Ticket       888 non-null    int32  \n",
      " 8   Fare         888 non-null    float64\n",
      " 9   Cabin        888 non-null    int32  \n",
      " 10  Embarked     888 non-null    int32  \n",
      "dtypes: float64(2), int32(4), int64(5)\n",
      "memory usage: 69.4 KB\n"
     ]
    }
   ],
   "source": [
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eefd628f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 정확도: 1.0000\n",
      "1 정확도: 0.7680\n",
      "1 최종 정확도: 0.7828\n",
      "2 정확도: 1.0000\n",
      "2 정확도: 0.8320\n",
      "2 최종 정확도: 0.8240\n",
      "3 정확도: 0.7823\n",
      "3 정확도: 0.8320\n",
      "3 최종 정확도: 0.8052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#classifier클래스 생성\n",
    "dt_clf=DecisionTreeClassifier(random_state=11)\n",
    "rf_clf=RandomForestClassifier(random_state=11)\n",
    "lr_clf=LogisticRegression(random_state=11)\n",
    "lr=LinearRegression(fit_intercept=True, normalize=True, n_jobs=None)\n",
    "gbm = lgb.LGBMRegressor(num_leaves=31,learning_rate=0.05, n_estimators=20)\n",
    "linear_model=Ridge(fit_intercept=False,solver='lsqr')\n",
    "#1. 의사결정나무\n",
    "dt_clf.fit(x_train,y_train)\n",
    "pred_train=dt_clf.predict(x_train)\n",
    "pred_val=dt_clf.predict(x_val)\n",
    "print('1 정확도: {0:.4f}'.format(accuracy_score(y_train, pred_train)))\n",
    "print('1 정확도: {0:.4f}'.format(accuracy_score(y_val, pred_val)))\n",
    "pred_test=dt_clf.predict(x_test)\n",
    "print('1 최종 정확도: {0:.4f}'.format(accuracy_score(y_test,pred_test)))\n",
    "\n",
    "#2. 랜덤포레스트\n",
    "rf_clf.fit(x_train,y_train)\n",
    "pred_train=rf_clf.predict(x_train)\n",
    "pred_val=rf_clf.predict(x_val)\n",
    "print('2 정확도: {0:.4f}'.format(accuracy_score(y_train, pred_train)))\n",
    "print('2 정확도: {0:.4f}'.format(accuracy_score(y_val, pred_val)))\n",
    "pred_test_rf_clf=rf_clf.predict(x_test)\n",
    "print('2 최종 정확도: {0:.4f}'.format(accuracy_score(y_test,pred_test_rf_clf)))\n",
    "#3. 로지스틱회귀\n",
    "lr_clf.fit(x_train,y_train)\n",
    "pred_train=lr_clf.predict(x_train)\n",
    "pred_val=lr_clf.predict(x_val)\n",
    "print('3 정확도: {0:.4f}'.format(accuracy_score(y_train, pred_train)))\n",
    "print('3 정확도: {0:.4f}'.format(accuracy_score(y_val, pred_val)))\n",
    "pred_test_lr_clf=lr_clf.predict(x_test)\n",
    "print('3 최종 정확도: {0:.4f}'.format(accuracy_score(y_test,pred_test_lr_clf)))\n",
    "\n",
    "\n",
    "#최종정확도에서 랜덤포레스트가 가장높다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9953c47",
   "metadata": {},
   "source": [
    "\n",
    "#### 랜덤포레스트 값이 최종적으로 높게 나오나 과적합된것을 볼 수 있었음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea674262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 정확도: 0.1535\n",
      "4 정확도: 0.1406\n",
      "4 최종 정확도: 0.1268\n",
      "4 최종 정확도(r2): 0.4702\n",
      "5 정확도: 0.1372\n",
      "5 정확도: 0.1350\n",
      "5 최종 정확도: 0.1389\n",
      "5 최종 정확도(r2): 0.4199\n",
      "6 정확도: 0.2231\n",
      "6 정확도: 0.2383\n",
      "6 최종 정확도: 0.2392\n",
      "6 최종 정확도(r2): 0.0008\n"
     ]
    }
   ],
   "source": [
    "#오류가 뜨는 모델\n",
    "#오류코드:Classification metrics can't handle a mix of binary and continuous targets\n",
    "#원인: 회귀모델인데 분류정확도평가를 사용하였기 때문이다.\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "#4.linear regression\n",
    "lr.fit(x_train,y_train)\n",
    "pred_train=lr.predict(x_train)\n",
    "pred_val=lr.predict(x_val)\n",
    "print('4 정확도: {0:.4f}'.format(mean_squared_error(y_train, pred_train)))\n",
    "print('4 정확도: {0:.4f}'.format(mean_squared_error(y_val, pred_val)))\n",
    "pred_test=lr.predict(x_test)\n",
    "print('4 최종 정확도: {0:.4f}'.format(mean_squared_error(y_test,pred_test)))\n",
    "print('4 최종 정확도(r2): {0:.4f}'.format(r2_score(y_test,pred_test)))\n",
    "\n",
    "\n",
    "#5. lgbm\n",
    "gbm.fit(x_train,y_train)\n",
    "pred_train=gbm.predict(x_train)\n",
    "pred_val=gbm.predict(x_val)\n",
    "print('5 정확도: {0:.4f}'.format(mean_squared_error(y_train, pred_train)))\n",
    "print('5 정확도: {0:.4f}'.format(mean_squared_error(y_val, pred_val)))\n",
    "pred_test=gbm.predict(x_test)\n",
    "print('5 최종 정확도: {0:.4f}'.format(mean_squared_error(y_test,pred_test)))\n",
    "print('5 최종 정확도(r2): {0:.4f}'.format(r2_score(y_test,pred_test)))\n",
    "\n",
    "\n",
    "#6.ridge\n",
    "linear_model.fit(x_train,y_train)\n",
    "pred_train=linear_model.predict(x_train)\n",
    "pred_val=linear_model.predict(x_val)\n",
    "print('6 정확도: {0:.4f}'.format(mean_squared_error(y_train, pred_train)))\n",
    "print('6 정확도: {0:.4f}'.format(mean_squared_error(y_val, pred_val)))\n",
    "pred_test=linear_model.predict(x_test)\n",
    "print('6 최종 정확도: {0:.4f}'.format(mean_squared_error(y_test,pred_test)))\n",
    "print('6 최종 정확도(r2): {0:.4f}'.format(r2_score(y_test,pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bc3176",
   "metadata": {},
   "source": [
    "####  linear regression이 가장 높음(r2 score& mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc621a99",
   "metadata": {},
   "source": [
    "# 교차검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4e462bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 로지스틱회귀 정확도: 0.8052\n",
      "기존 랜덤포레스트 정확도: 0.8240\n"
     ]
    }
   ],
   "source": [
    "#1.kfold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#만들기(kfold)\n",
    "kfold=KFold(n_splits=5)\n",
    "\n",
    "#적용하기\n",
    "\n",
    "\n",
    "\n",
    "print('기존 로지스틱회귀 정확도: {0:.4f}'.format(accuracy_score(y_test,pred_test_lr_clf)))\n",
    "print('기존 랜덤포레스트 정확도: {0:.4f}'.format(accuracy_score(y_test,pred_test_rf_clf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6ee6559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#case1\n",
    "score_list_lr=cross_val_score(lr_clf, X_titanic_df,y_titanic_df)\n",
    "score_list_rf=cross_val_score(rf_clf, X_titanic_df,y_titanic_df)\n",
    "\n",
    "result_lr=list(map(lambda x:'{score:.2f}'.format(score=x),score_list_lr))\n",
    "result_rf=list(map(lambda x:'{score:.2f}'.format(score=x),score_list_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70db1ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로직스틱 회귀 교차검증 후 예측값: ['0.74', '0.80', '0.78', '0.77', '0.80']\n",
      "랜덤 포레스트 교차검증 후 예측값: ['0.74', '0.79', '0.85', '0.81', '0.86']\n"
     ]
    }
   ],
   "source": [
    "print('로직스틱 회귀 교차검증 후 예측값:',result_lr)\n",
    "\n",
    "print('랜덤 포레스트 교차검증 후 예측값:',result_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c4a4c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 k fold: [0.74157303 0.79775281 0.7752809  0.76836158 0.79661017]\n",
      "랜덤 포레스트 k fold: [0.74157303 0.78651685 0.84831461 0.8079096  0.85875706]\n"
     ]
    }
   ],
   "source": [
    "## 교차검증\n",
    "#case2\n",
    "score_list=cross_val_score(lr_clf, X_titanic_df,y_titanic_df, cv=5)\n",
    "print('로지스틱 k fold:',score_list)\n",
    "\n",
    "score_list=cross_val_score(rf_clf, X_titanic_df,y_titanic_df, cv=5)\n",
    "print('랜덤 포레스트 k fold:',score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08009f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증의 정확도0.7416\n",
      "교차 검증의 정확도0.7978\n",
      "교차 검증의 정확도0.7753\n",
      "교차 검증의 정확도0.7684\n",
      "교차 검증의 정확도0.7966\n",
      "평균 정확도: 0.7759156985970926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#case3\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores=cross_val_score(lr_clf, X_titanic_df, y_titanic_df, cv=5)\n",
    "for a, b in enumerate(scores):\n",
    "    print('교차 검증의 정확도{1:.4f}'.format(a,b))\n",
    "#평균은?    \n",
    "print('평균 정확도:',np.mean(scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c5010b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.7559798  0.7559798         nan 0.75191919 0.75191919\n",
      "        nan 0.78822222 0.78620202        nan 0.79018182 0.79024242]\n",
      "  warnings.warn(\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 237, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ns451\\Documents\\anaconda_1\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [  nan 0.808 0.8     nan 0.824 0.848   nan 0.824 0.832   nan 0.816 0.832]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#GridSearchCV : 최적 하이퍼 파라미터를 찾아서 성능을 측정하기\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "parameters={'max_depth':[2,3,5,10],'min_samples_split':[2,3,5],'min_samples_split':[1,5,8]}\n",
    "\n",
    "#\n",
    "grid_clf=GridSearchCV(rf_clf, param_grid=parameters, scoring='accuracy',cv=5)\n",
    "\n",
    "#\n",
    "grid_clf.fit(x_train,y_train)\n",
    "grid_clf.fit(x_val, y_val)\n",
    "#\n",
    "best_clf=grid_clf.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pred_val=best_clf.predict(x_val)\n",
    "accuracy_val=accuracy_score(pred_val, y_val)\n",
    "\n",
    "\n",
    "pred_test=best_clf.predict(x_test)\n",
    "accuracy_test=accuracy_score(pred_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c5ac0044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=3, min_samples_split=8, random_state=11)\n",
      "랜덤포레스트 최적의 파라미터 구한 후 정확도 측정시 train 정확도0.8880\n",
      "랜덤포레스트 최적의 파라미터 구한 후 정확도 측정시 validation 정확도 0.8352\n"
     ]
    }
   ],
   "source": [
    "print(best_clf)\n",
    "print(\"랜덤포레스트 최적의 파라미터 구한 후 정확도 측정시 train 정확도{0:.4f}\".format(accuracy_val))\n",
    "print(\"랜덤포레스트 최적의 파라미터 구한 후 정확도 측정시 validation 정확도 {0:.4f}\".format(accuracy_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
